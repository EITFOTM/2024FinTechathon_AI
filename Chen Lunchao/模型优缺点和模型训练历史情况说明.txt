训练Cnn时：
如果使用Adam优化器，第一次epoch的准确率最高，之后准确率下降，并保持一定的值不动，可能陷入局部最优了。
使用SGD优化器时，平均损失和准确率在刚开始几轮基本不变，但之后会突然变化和增加，平均损失也有时会突然增大再减少。
所以该模型有时不是很稳定。

训练EffifientNet时：
对比CNN模型，该模型在一开始就有很好的效果，且之后的准确率能稳定提高，平均损失也保持下降趋势。
所以EffifientNet的稳定性非常好。而且平均每轮训练时间并没有比CNN模型多很多，这大大节约了时间成本。
不过该模型对于GPU的内存需求可能更大，在batch size为96，优化器为Adam的情况下，
需要9.8GB左右的GPU专用内存。而CNN模型在同等情况下，只需要8.2GB左右的GPU专用内存。

CNN
优点：
1特征提取能力强：CNN通过卷积层和池化层能够有效地提取图像中的局部特征。
2参数共享：卷积操作使得模型参数量相对较少，提高了计算效率。
3平移不变性：CNN对图像中的平移具有一定的鲁棒性，可以更好地处理图像的位移。
4广泛应用：CNN已经经过大量研究和应用，存在许多成熟的架构和实践经验。
缺点：
1结构单一：传统的CNN架构一般较为固定，难以适应不同规模的问题。
2计算资源消耗大：对于高分辨率图像，传统CNN需要大量的计算资源和存储空间。
3训练难度：在深层网络中，梯度消失或爆炸问题可能导致训练困难。

EfficientNet
优点：
1高效性：EfficientNet使用复合缩放方法，同时调整网络的深度、宽度和分辨率，从而在保持较高性能的同时减少计算开销。
2精度高：在ImageNet等标准数据集上，EfficientNet通常表现出比其他网络更好的准确率。
3灵活性强：模型可以根据具体需求选择合适的版本（如B0到B7），以便在速度和准确率之间取得良好平衡。
4参数数量少：相比于其他深度网络，EfficientNet在得到类似甚至更好的效果时，往往参数数量更少，更加节省内存和计算资源。
通过统一的复合系数，EfficientNet可以在不同的计算资源下进行缩放，从而设计出轻量级的模型，适用于计算资源受限的场景‌。
5可迁移性‌：EfficientNet可以在不同的任务和数据集上进行迁移学习。由于EfficientNet在搜索过程中采用了一些通用的设计原则，
因此在其他任务和数据集上使用也能取得较好的效果‌。
缺点：
1复杂性：EfficientNet的设计和实现相对复杂，对于初学者来说可能不易理解。
2依赖于基础模型：EfficientNet是基于MobileNet和其他网络进行改进的，因此在某些情况下可能不如专门针对特定任务设计的网络表现好。
3训练时间长：虽然推理效率高，但由于其结构复杂，在训练阶段可能需要更长的时间来收敛。
